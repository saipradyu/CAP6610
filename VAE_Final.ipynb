{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "VAE_Final.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "72iTNQCg6Ec_"
      },
      "source": [
        "from IPython import display\r\n",
        "import torch\r\n",
        "import sys\r\n",
        "from torch import nn, optim\r\n",
        "from torch.autograd.variable import Variable\r\n",
        "from torchvision import transforms, datasets\r\n",
        "import torch.nn.functional as F\r\n",
        "from torchvision.utils import save_image\r\n",
        "content_folder = './'\r\n",
        "\r\n",
        "img_transform = transforms.Compose([\r\n",
        "    transforms.ToTensor(),\r\n",
        "    transforms.Normalize((0.5,),(0.5,)),\r\n",
        "])\r\n",
        "\r\n",
        "\r\n",
        "train_data = datasets.MNIST(\r\n",
        "    root='./content/mnist',\r\n",
        "    train=True,\r\n",
        "    download=True,\r\n",
        "    transform=img_transform\r\n",
        ")\r\n",
        "\r\n",
        "test_data = datasets.MNIST(\r\n",
        "    root='./content/mnist',\r\n",
        "    train=False,\r\n",
        "    download=True,\r\n",
        "    transform=img_transform\r\n",
        ")\r\n",
        "\r\n",
        "train_loader = torch.utils.data.DataLoader(dataset=train_data, batch_size=100, shuffle=True)\r\n",
        "test_loader = torch.utils.data.DataLoader(dataset=test_data, batch_size=100, shuffle=False)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "70madYPq-J8x"
      },
      "source": [
        "class VAE(nn.Module):\r\n",
        "    def __init__(self, x_dim, h_dim1, h_dim2, z_dim):\r\n",
        "        super(VAE, self).__init__()\r\n",
        "        \r\n",
        "        # encoder layers\r\n",
        "        self.fc1 =  nn.Sequential( \r\n",
        "              nn.Linear(x_dim, 1024),\r\n",
        "              nn.LeakyReLU(0.2),\r\n",
        "              nn.Dropout(0.3)\r\n",
        "            )\r\n",
        "        self.fc2 =  nn.Sequential( \r\n",
        "              nn.Linear(1024, h_dim1),\r\n",
        "              nn.LeakyReLU(0.2),\r\n",
        "              nn.Dropout(0.3)\r\n",
        "            )\r\n",
        "        self.fc3 =nn.Sequential(  \r\n",
        "              nn.Linear(h_dim1, h_dim2),\r\n",
        "              nn.LeakyReLU(0.2),\r\n",
        "              nn.Dropout(0.3)\r\n",
        "        )\r\n",
        "        self.fc41 = nn.Sequential(  \r\n",
        "              nn.Linear(h_dim2, z_dim),\r\n",
        "              nn.LeakyReLU(0.2),\r\n",
        "              nn.Dropout(0.3)\r\n",
        "            )\r\n",
        "        self.fc42 = nn.Sequential(  \r\n",
        "              nn.Linear(h_dim2, z_dim),\r\n",
        "              nn.LeakyReLU(0.2),\r\n",
        "              nn.Dropout(0.3)\r\n",
        "            )\r\n",
        "        \r\n",
        "        # decoder layers\r\n",
        "        self.fc5 =  nn.Sequential( \r\n",
        "              nn.Linear(z_dim, h_dim2),\r\n",
        "              nn.LeakyReLU(0.2),\r\n",
        "            )\r\n",
        "        self.fc6 = nn.Sequential(\r\n",
        "              nn.Linear(h_dim2, h_dim1),\r\n",
        "              nn.LeakyReLU(0.2)\r\n",
        "            ) \r\n",
        "        self.fc7 =  nn.Sequential(\r\n",
        "              nn.Linear(h_dim1, 1024),\r\n",
        "              nn.LeakyReLU(0.2)\r\n",
        "            )\r\n",
        "        self.fc8 =  nn.Sequential(\r\n",
        "              nn.Linear(1024, x_dim),\r\n",
        "              nn.LeakyReLU(0.2))\r\n",
        "        \r\n",
        "    def encoder(self, x):\r\n",
        "        h = self.fc1(x)\r\n",
        "        h = self.fc2(h)\r\n",
        "        h = self.fc3(h)\r\n",
        "        return self.fc41(h), self.fc42(h) # mean, log of variance\r\n",
        "    \r\n",
        "    def sampling(self, mu, log_var):\r\n",
        "        std = torch.exp(0.5*log_var)\r\n",
        "        eps = torch.randn_like(std)\r\n",
        "        return eps.mul(std).add_(mu) # return a latent vector sample z from approx prior\r\n",
        "        \r\n",
        "    def decoder(self, z):\r\n",
        "        h = self.fc5(z)\r\n",
        "        h = self.fc6(h)\r\n",
        "        h = self.fc7(h)\r\n",
        "        h = self.fc8(h)\r\n",
        "        return torch.sigmoid(h) \r\n",
        "    \r\n",
        "    def forward(self, x):\r\n",
        "        mu, log_var = self.encoder(x)\r\n",
        "        z = self.sampling(mu, log_var)\r\n",
        "        return self.decoder(z), mu, log_var\r\n",
        "\r\n",
        "vae = VAE(x_dim=784, h_dim1= 512, h_dim2=256, z_dim=2)  "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4odqJYi-0vAh"
      },
      "source": [
        "def loss_function(recon_x, x, mu, log_var):\r\n",
        "    BCE = F.binary_cross_entropy(recon_x, x, reduction='sum')\r\n",
        "    KLD = -0.5 * torch.sum(1 + log_var - mu.pow(2) - log_var.exp())\r\n",
        "    return BCE + KLD\r\n",
        "\r\n",
        "def train_VAE(optimizer, data):\r\n",
        "    \r\n",
        "    optimizer.zero_grad()\r\n",
        "    recon_batch, mu, log_var = vae(data)\r\n",
        "    error = loss_function(recon_batch, data, mu, log_var)\r\n",
        "    error.backward()\r\n",
        "    optimizer.step()\r\n",
        "    return error\r\n",
        "    \r\n",
        "def img_to_vector(img):\r\n",
        "    return img.view(img.size(0), 784)\r\n",
        "\r\n",
        "def vector_to_img(vector):\r\n",
        "    return vector.view(vector.size(0), 1, 28, 28)    \r\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iO6kzd250wPd"
      },
      "source": [
        "v_optimizer = optim.Adam(vae.parameters(), lr=0.0002)\r\n",
        "num_epochs = 300\r\n",
        "num_test_samples = 64\r\n",
        "\r\n",
        "for epoch in range(num_epochs):\r\n",
        "    vae.train()\r\n",
        "    train_loss = 0\r\n",
        "    for n_batch, (real_batch,_) in enumerate(train_loader):\r\n",
        "        real_data = Variable(img_to_vector(real_batch))\r\n",
        "        loss = train_VAE(v_optimizer,real_data)\r\n",
        "        train_loss += loss.item()\r\n",
        "        \r\n",
        "        \r\n",
        "        if n_batch % 100 == 0:\r\n",
        "            display.clear_output(True)\r\n",
        "            z = torch.randn(num_test_samples, 2)\r\n",
        "            sample = vae.decoder(z)\r\n",
        "            test_images = vector_to_img(sample).data.cpu()\r\n",
        "            save_image(test_images, f\"./content/img_{epoch}_{n_batch}.png\", normalize=True)\r\n",
        "                        \r\n",
        "    vae.eval()\r\n",
        "    test_loss= 0\r\n",
        "    with torch.no_grad():\r\n",
        "        for data, _ in test_loader:\r\n",
        "            data = data\r\n",
        "            real_data = Variable(img_to_vector(real_batch))\r\n",
        "            recon, mu, log_var = vae(real_data)\r\n",
        "            \r\n",
        "            test_loss += loss_function(recon, real_data, mu, log_var).item()\r\n",
        "        \r\n",
        "    test_loss /= len(test_loader.dataset)\r\n",
        "    print('Loss for test data: {:.8f}'.format(test_loss))"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}