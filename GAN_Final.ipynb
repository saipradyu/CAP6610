{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "GAN_Final.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "zmhx0e_uoEqh"
      },
      "source": [
        "from IPython import display\r\n",
        "import torch\r\n",
        "import sys\r\n",
        "from torch import nn, optim\r\n",
        "from torch.autograd.variable import Variable\r\n",
        "from torchvision import transforms, datasets\r\n",
        "import torch.nn.functional as F\r\n",
        "from torchvision.utils import save_image\r\n",
        "content_folder = './'\r\n",
        "\r\n",
        "img_transform = transforms.Compose([\r\n",
        "    transforms.ToTensor(),\r\n",
        "    transforms.Normalize((0.5,),(0.5,)),\r\n",
        "])\r\n",
        "\r\n",
        "\r\n",
        "data = datasets.MNIST(\r\n",
        "    root='./content/mnist',\r\n",
        "    train=True,\r\n",
        "    download=True,\r\n",
        "    transform=img_transform\r\n",
        ")\r\n",
        "data_loader = torch.utils.data.DataLoader(data, batch_size=100, shuffle=True)\r\n",
        "num_batches = len(data_loader)\r\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Pk4KmoQUqnqw"
      },
      "source": [
        "class Discriminator(torch.nn.Module):\r\n",
        "    def __init__(self):\r\n",
        "        super(Discriminator, self).__init__()\r\n",
        "        n_features = 784\r\n",
        "        n_out = 1\r\n",
        "        \r\n",
        "        self.hidden0 = nn.Sequential( \r\n",
        "            nn.Linear(n_features, 1024),\r\n",
        "            nn.LeakyReLU(0.2),\r\n",
        "            nn.Dropout(0.3)\r\n",
        "        )\r\n",
        "        self.hidden1 = nn.Sequential(\r\n",
        "            nn.Linear(1024, 512),\r\n",
        "            nn.LeakyReLU(0.2),\r\n",
        "            nn.Dropout(0.3)\r\n",
        "        )\r\n",
        "        self.hidden2 = nn.Sequential(\r\n",
        "            nn.Linear(512, 256),\r\n",
        "            nn.LeakyReLU(0.2),\r\n",
        "            nn.Dropout(0.3)\r\n",
        "        )\r\n",
        "        self.out = nn.Sequential(\r\n",
        "            torch.nn.Linear(256, n_out),\r\n",
        "            torch.nn.Sigmoid()\r\n",
        "        )\r\n",
        "\r\n",
        "    def forward(self, x):\r\n",
        "        x = self.hidden0(x)\r\n",
        "        x = self.hidden1(x)\r\n",
        "        x = self.hidden2(x)\r\n",
        "        x = self.out(x)\r\n",
        "        return x\r\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xA8jnEN5saVv"
      },
      "source": [
        "class Generator(torch.nn.Module):\r\n",
        "  def __init__(self):\r\n",
        "      super(Generator, self).__init__()\r\n",
        "      n_features = 100\r\n",
        "      n_out = 784\r\n",
        "      \r\n",
        "      self.hidden0 = nn.Sequential(\r\n",
        "          nn.Linear(n_features, 256),\r\n",
        "          nn.LeakyReLU(0.2)\r\n",
        "      )\r\n",
        "      self.hidden1 = nn.Sequential(            \r\n",
        "          nn.Linear(256, 512),\r\n",
        "          nn.LeakyReLU(0.2)\r\n",
        "      )\r\n",
        "      self.hidden2 = nn.Sequential(\r\n",
        "          nn.Linear(512, 1024),\r\n",
        "          nn.LeakyReLU(0.2)\r\n",
        "      )\r\n",
        "      \r\n",
        "      self.out = nn.Sequential(\r\n",
        "          nn.Linear(1024, n_out),\r\n",
        "          nn.Tanh()\r\n",
        "      )\r\n",
        "\r\n",
        "  def forward(self, x):\r\n",
        "      x = self.hidden0(x)\r\n",
        "      x = self.hidden1(x)\r\n",
        "      x = self.hidden2(x)\r\n",
        "      x = self.out(x)\r\n",
        "      return x  \r\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AYGfIQssssXJ"
      },
      "source": [
        "discriminator = Discriminator()\r\n",
        "generator = Generator()\r\n",
        "if torch.cuda.is_available():\r\n",
        "    discriminator.cuda()\r\n",
        "    generator.cuda()\r\n",
        "\r\n",
        "d_optimizer = optim.Adam(discriminator.parameters(), lr=0.0002)\r\n",
        "g_optimizer = optim.Adam(generator.parameters(), lr=0.0002)\r\n",
        "\r\n",
        "loss = nn.BCELoss()\r\n",
        "d_steps = 1"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CAkqjTJ_tNcE"
      },
      "source": [
        "def check_data_real(size):\r\n",
        "    data = Variable(torch.ones(size, 1))\r\n",
        "    if torch.cuda.is_available(): return data.cuda()\r\n",
        "    return data\r\n",
        "\r\n",
        "def noise(size):\r\n",
        "    n = Variable(torch.randn(size, 100))\r\n",
        "    if torch.cuda.is_available(): return n.cuda() \r\n",
        "    return n\r\n",
        "\r\n",
        "def check_data_fake(size):\r\n",
        "    data = Variable(torch.zeros(size, 1))\r\n",
        "    if torch.cuda.is_available(): return data.cuda()\r\n",
        "    return data\r\n",
        "    \r\n",
        "def images_to_vectors(images):\r\n",
        "    return images.view(images.size(0), 784)\r\n",
        "\r\n",
        "def vectors_to_images(vectors):\r\n",
        "    return vectors.view(vectors.size(0), 1, 28, 28)\r\n",
        "\r\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mKmDWJwjtmbV"
      },
      "source": [
        "def train_discriminator(optimizer, real_data, fake_data):\r\n",
        "    optimizer.zero_grad()\r\n",
        "    \r\n",
        "    pred_real = discriminator(real_data)\r\n",
        "    error_real = loss(pred_real, check_data_real(real_data.size(0)))\r\n",
        "    error_real.backward()\r\n",
        "\r\n",
        "    pred_fake = discriminator(fake_data)\r\n",
        "    error_fake = loss(pred_fake, check_data_fake(real_data.size(0)))\r\n",
        "    error_fake.backward()\r\n",
        "    \r\n",
        "    optimizer.step()\r\n",
        "    return error_real + error_fake, pred_real, pred_fake\r\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MxoL9HmwuML0"
      },
      "source": [
        "def train_generator(optimizer, fake_data):\r\n",
        "    optimizer.zero_grad()\r\n",
        "    prediction = discriminator(fake_data)\r\n",
        "    error = loss(prediction, check_data_real(prediction.size(0)))\r\n",
        "    error.backward()\r\n",
        "    optimizer.step()\r\n",
        "    return error\r\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "1Onz2b_ZuirI"
      },
      "source": [
        "num_test_samples = 64\r\n",
        "test_noise = noise(num_test_samples)\r\n",
        "num_epochs = 300\r\n",
        "\r\n",
        "for epoch in range(num_epochs):\r\n",
        "    for n_batch, (real_batch,_) in enumerate(data_loader):\r\n",
        "\r\n",
        "        real_data = Variable(images_to_vectors(real_batch))\r\n",
        "        if torch.cuda.is_available(): real_data = real_data.cuda()\r\n",
        "        fake_data = generator(noise(real_data.size(0))).detach()\r\n",
        "        d_error, d_pred_real, d_pred_fake = train_discriminator(d_optimizer,\r\n",
        "                                                                real_data, fake_data)\r\n",
        "\r\n",
        "        fake_data = generator(noise(real_batch.size(0)))\r\n",
        "        g_error = train_generator(g_optimizer, fake_data)\r\n",
        "\r\n",
        "        print(f\"Generator loss: {g_error:.8f}, Discriminator loss: {d_error:.8f}\")\r\n",
        "\r\n",
        "        if (n_batch) % 100 == 0:\r\n",
        "            display.clear_output(True)\r\n",
        "            test_images = vectors_to_images(generator(test_noise)).data.cpu()\r\n",
        "            save_image(test_images, f\"./content/img_{epoch}_{n_batch}.png\", normalize=True)\r\n",
        "\r\n"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}